{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXnAZFDkCdKP",
        "outputId": "6f8ce61e-10b3-40cb-b09b-d66b85bfcd7d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "jyKrt1wOwCUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Iris Dataset\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = iris.data.features\n",
        "y = iris.data.targets"
      ],
      "metadata": {
        "id": "Ss7ayza94Ydv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.info())\n",
        "print(y.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUe0DC2UCihf",
        "outputId": "6505cf21-c3cb-43c8-fa62-f65b6e8dd318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal length  150 non-null    float64\n",
            " 1   sepal width   150 non-null    float64\n",
            " 2   petal length  150 non-null    float64\n",
            " 3   petal width   150 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.8 KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   class   150 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.3+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing the data\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Standardizing features, because we are using a gradient based algorithm\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "# OneHotEncoding labels, because they are given as strings\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0CpbOcmnExMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating variables\n",
        "np.random.seed(42) # Setting a seed, so the code is reproducible\n",
        "\n",
        "n_instances = X_train.shape[0]\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = y_train.shape[1]\n",
        "\n",
        "W = np.random.randn(n_features, n_classes) # Matrix of weights\n",
        "b = np.zeros((1, n_classes))\n",
        "\n",
        "# Creating hyperparameters\n",
        "learning_rate = 0.1\n",
        "max_epochs = 1000"
      ],
      "metadata": {
        "id": "WTlqtrZyEttw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(logits): # The model we are going to optimize\n",
        "  exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
        "  return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
        "\n",
        "def loss(y, y_predicted, m): # Cross-entropy loss function\n",
        "  return -np.sum(y * np.log(y_predicted)) / m # m = n_instances\n",
        "\n",
        "def gradient(y_predicted, y, m): # m = n_instances\n",
        "  error = y_predicted - y\n",
        "  dW = X_train.T @ error / m # gradient of W weight matrix\n",
        "  db = np.sum(error, axis=0) / m # Gradient of b bias\n",
        "  return dW, db"
      ],
      "metadata": {
        "id": "al2O4WxqEu_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1000 # Number of epochs (how many times model goes through whole dataset once)\n",
        "patience = 15 # Number of epochs to stop training if there is no improvement\n",
        "count = patience # Counter that will be usede for early stopping\n",
        "best_loss = np.inf # Variable that stores the best loss\n",
        "\n",
        "# Softmax regression model training\n",
        "for epoch in range(n_epochs):\n",
        "  logits = X_train @ W + b # Logit = raw output score\n",
        "  y_prediction = softmax(logits) # Predicting using softmax\n",
        "\n",
        "  current_loss = loss(y_train, y_prediction, n_instances) # Computing current loss\n",
        "\n",
        "  if current_loss < best_loss: # Early stopping mechanism\n",
        "    best_loss = current_loss\n",
        "    count = patience # Counter\n",
        "  else:\n",
        "    count -= 1 # Counter decrease\n",
        "\n",
        "  if count == 0: # If statement for Early stopping\n",
        "    print(f'Early stopping has occured at {epoch} epoch.')\n",
        "\n",
        "  dW, db = gradient(y_prediction, y_train, n_instances) # Getting gradients\n",
        "  W = W - learning_rate * dW # Applying changes\n",
        "  b = b - learning_rate * db # Applying changes"
      ],
      "metadata": {
        "id": "cJ9KNbawxUs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "test_logits = X_test @ W + b\n",
        "y_test_pred = softmax(test_logits)\n",
        "\n",
        "y_test_pred_class = np.argmax(y_test_pred, axis=1) # Getting class label of highest prediction\n",
        "y_test_actual_class = np.argmax(y_test, axis=1)  # True labels from one-hot encoding\n",
        "\n",
        "accuracy = np.mean(y_test_pred_class == y_test_actual_class)\n",
        "print(f'Accuracy score for Softmax regression model: {round(accuracy, 2) * 100}%')"
      ],
      "metadata": {
        "id": "mYCqsy4_vqjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16433870-cbff-4a00-9ab8-c897cc094f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score for Softmax regression model: 100.0%\n"
          ]
        }
      ]
    }
  ]
}